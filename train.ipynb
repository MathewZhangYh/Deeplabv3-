{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0328d1-3a33-4eb5-b6ad-61e3ffa41677",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nets.deeplabv3_plus import DeepLab\n",
    "\n",
    "from utils.utils_training import get_lr_scheduler, set_optimizer_lr\n",
    "from utils.utils_logs import LossHistory\n",
    "from utils.dataloader import DeeplabDataset\n",
    "from utils.utils_fit import fit_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bfb07",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load model and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec8ab7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of keys which fial loading: 0\n"
     ]
    }
   ],
   "source": [
    "Cuda = True\n",
    "num_classes = 2\n",
    "model_path = \"model/deeplabv3+_model.pth\"\n",
    "dataset_path = 'weizmann_horse_db'\n",
    "save_dir = 'logs'\n",
    "\n",
    "input_shape = [512, 512]\n",
    "def weights_init(net):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    net.apply(init_func)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeepLab(num_classes=num_classes)\n",
    "weights_init(model)\n",
    "\n",
    "# 根据预训练权重的Key和模型的Key进行加载\n",
    "model_dict      = model.state_dict()\n",
    "pretrained_dict = torch.load(model_path, map_location = device)\n",
    "\n",
    "load_key, no_load_key, temp_dict = [], [], {}\n",
    "for k, v in pretrained_dict.items():\n",
    "    if k in model_dict.keys() and np.shape(model_dict[k]) == np.shape(v):\n",
    "        temp_dict[k] = v\n",
    "        load_key.append(k)\n",
    "    else:\n",
    "        no_load_key.append(k)\n",
    "model_dict.update(temp_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "time_str = datetime.datetime.strftime(datetime.datetime.now(),'%Y_%m_%d_%H_%M_%S')\n",
    "log_dir = os.path.join(save_dir, \"loss_\" + str(time_str))\n",
    "loss_history = LossHistory(log_dir, model, input_shape=input_shape)\n",
    "model_train = model.train()\n",
    "\n",
    "if Cuda:\n",
    "    model_train = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    model_train = model_train.cuda()\n",
    "print('The numbers of keys which fail loading:',len(no_load_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73191b5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df83bcd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Epoch = 10\n",
    "batch_size = 4\n",
    "def collate_function(batch):\n",
    "    images = []\n",
    "    pngs = []\n",
    "    seg_labels = []\n",
    "    for img, png, labels in batch:\n",
    "        images.append(img)\n",
    "        pngs.append(png)\n",
    "        seg_labels.append(labels)\n",
    "    images = torch.from_numpy(np.array(images)).type(torch.FloatTensor)\n",
    "    pngs = torch.from_numpy(np.array(pngs)).long()\n",
    "    seg_labels = torch.from_numpy(np.array(seg_labels)).type(torch.FloatTensor)\n",
    "    return images, pngs, seg_labels\n",
    "\n",
    "with open(os.path.join(dataset_path, \"datasets/train.txt\"),\"r\") as f:\n",
    "        train_lines = f.readlines()\n",
    "with open(os.path.join(dataset_path, \"datasets/val.txt\"),\"r\") as f:\n",
    "        val_lines = f.readlines()\n",
    "num_train = len(train_lines)\n",
    "num_val   = len(val_lines)\n",
    "\n",
    "train_dataset = DeeplabDataset(train_lines, input_shape, num_classes, True, dataset_path)\n",
    "val_dataset = DeeplabDataset(val_lines, input_shape, num_classes, False, dataset_path)\n",
    "\n",
    "train_set = DataLoader(train_dataset, shuffle = True, batch_size = batch_size, pin_memory=True,\n",
    "                 drop_last = True, collate_fn = collate_function)\n",
    "val_set = DataLoader(val_dataset  , shuffle = True, batch_size = batch_size, pin_memory=True,\n",
    "                     drop_last = True, collate_fn = collate_function)\n",
    "# 判断每一个epoch的长度\n",
    "epoch_step = num_train // batch_size\n",
    "epoch_step_val = num_val // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef9e5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4c5635",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "Init_lr = 7e-3\n",
    "Min_lr = Init_lr * 0.01\n",
    "\n",
    "nbs  = 16\n",
    "lr_limit_max = 1e-1\n",
    "lr_limit_min = 5e-4\n",
    "# 根据batch_size，自适应调整学习率\n",
    "Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "# SGD优化器\n",
    "optimizer = optim.SGD(model.parameters(), Init_lr_fit, momentum = momentum, nesterov=True, weight_decay = weight_decay)\n",
    "# 获得学习率下降的公式\n",
    "lr_scheduler_func = get_lr_scheduler(Init_lr_fit, Min_lr_fit, Epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f7e3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb3cc096-ecc1-442d-b601-659edf7f2a21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch(train) 1/10: 100%|█████████████████████████████████████████████| 69/69 [00:30<00:00,  2.27it/s, train_loss=0.118]\n",
      "Epoch(valid) 1/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  5.09it/s, val_loss=0.0991]\n",
      "Epoch(train) 2/10: 100%|█████████████████████████████████████████████| 69/69 [00:25<00:00,  2.72it/s, train_loss=0.128]\n",
      "Epoch(valid) 2/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  4.95it/s, val_loss=0.0984]\n",
      "Epoch(train) 3/10: 100%|█████████████████████████████████████████████| 69/69 [00:25<00:00,  2.70it/s, train_loss=0.118]\n",
      "Epoch(valid) 3/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  5.00it/s, val_loss=0.0912]\n",
      "Epoch(train) 4/10: 100%|█████████████████████████████████████████████| 69/69 [00:25<00:00,  2.70it/s, train_loss=0.126]\n",
      "Epoch(valid) 4/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  4.88it/s, val_loss=0.0936]\n",
      "Epoch(train) 5/10: 100%|█████████████████████████████████████████████| 69/69 [00:26<00:00,  2.56it/s, train_loss=0.109]\n",
      "Epoch(valid) 5/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  4.21it/s, val_loss=0.0905]\n",
      "Epoch(train) 6/10: 100%|██████████████████████████████████████████████| 69/69 [00:28<00:00,  2.39it/s, train_loss=0.11]\n",
      "Epoch(valid) 6/10: 100%|███████████████████████████████████████████████| 12/12 [00:02<00:00,  4.65it/s, val_loss=0.085]\n",
      "Epoch(train) 7/10: 100%|████████████████████████████████████████████| 69/69 [00:26<00:00,  2.57it/s, train_loss=0.0977]\n",
      "Epoch(valid) 7/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  4.59it/s, val_loss=0.0843]\n",
      "Epoch(train) 8/10: 100%|█████████████████████████████████████████████| 69/69 [00:27<00:00,  2.55it/s, train_loss=0.111]\n",
      "Epoch(valid) 8/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  4.50it/s, val_loss=0.0872]\n",
      "Epoch(train) 9/10: 100%|█████████████████████████████████████████████| 69/69 [00:26<00:00,  2.62it/s, train_loss=0.106]\n",
      "Epoch(valid) 9/10: 100%|██████████████████████████████████████████████| 12/12 [00:02<00:00,  4.86it/s, val_loss=0.0864]\n",
      "Epoch(train) 10/10: 100%|███████████████████████████████████████████| 69/69 [00:26<00:00,  2.60it/s, train_loss=0.0948]\n",
      "Epoch(valid) 10/10: 100%|█████████████████████████████████████████████| 12/12 [00:02<00:00,  4.60it/s, val_loss=0.0855]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(Epoch):\n",
    "    set_optimizer_lr(optimizer, lr_scheduler_func, epoch)\n",
    "    fit_one_epoch(model_train, model, loss_history, optimizer, epoch, Epoch, epoch_step, epoch_step_val,\n",
    "                  train_set, val_set, Cuda, num_classes, save_dir)\n",
    "loss_history.writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch1_2]",
   "language": "python",
   "name": "conda-env-pytorch1_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
